{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Array([[-1.        , -1.        , -1.        ],\n",
      "       [-0.97979796, -0.97979796, -0.97979796],\n",
      "       [-0.9595959 , -0.9595959 , -0.9595959 ],\n",
      "       [-0.939394  , -0.939394  , -0.939394  ],\n",
      "       [-0.91919196, -0.91919196, -0.91919196],\n",
      "       [-0.8989899 , -0.8989899 , -0.8989899 ],\n",
      "       [-0.8787879 , -0.8787879 , -0.8787879 ],\n",
      "       [-0.85858583, -0.85858583, -0.85858583],\n",
      "       [-0.8383838 , -0.8383838 , -0.8383838 ],\n",
      "       [-0.81818175, -0.81818175, -0.81818175],\n",
      "       [-0.79797983, -0.79797983, -0.79797983],\n",
      "       [-0.7777778 , -0.7777778 , -0.7777778 ],\n",
      "       [-0.75757575, -0.75757575, -0.75757575],\n",
      "       [-0.7373737 , -0.7373737 , -0.7373737 ],\n",
      "       [-0.71717167, -0.71717167, -0.71717167],\n",
      "       [-0.69696975, -0.69696975, -0.69696975],\n",
      "       [-0.6767677 , -0.6767677 , -0.6767677 ],\n",
      "       [-0.65656567, -0.65656567, -0.65656567],\n",
      "       [-0.6363636 , -0.6363636 , -0.6363636 ],\n",
      "       [-0.6161616 , -0.6161616 , -0.6161616 ],\n",
      "       [-0.59595966, -0.59595966, -0.59595966],\n",
      "       [-0.5757575 , -0.5757575 , -0.5757575 ],\n",
      "       [-0.5555556 , -0.5555556 , -0.5555556 ],\n",
      "       [-0.53535354, -0.53535354, -0.53535354],\n",
      "       [-0.5151515 , -0.5151515 , -0.5151515 ],\n",
      "       [-0.49494955, -0.49494955, -0.49494955],\n",
      "       [-0.47474745, -0.47474745, -0.47474745],\n",
      "       [-0.45454547, -0.45454547, -0.45454547],\n",
      "       [-0.43434346, -0.43434346, -0.43434346],\n",
      "       [-0.41414142, -0.41414142, -0.41414142],\n",
      "       [-0.39393938, -0.39393938, -0.39393938],\n",
      "       [-0.37373737, -0.37373737, -0.37373737],\n",
      "       [-0.35353538, -0.35353538, -0.35353538],\n",
      "       [-0.33333328, -0.33333328, -0.33333328],\n",
      "       [-0.31313133, -0.31313133, -0.31313133],\n",
      "       [-0.2929293 , -0.2929293 , -0.2929293 ],\n",
      "       [-0.27272725, -0.27272725, -0.27272725],\n",
      "       [-0.2525253 , -0.2525253 , -0.2525253 ],\n",
      "       [-0.2323232 , -0.2323232 , -0.2323232 ],\n",
      "       [-0.21212122, -0.21212122, -0.21212122],\n",
      "       [-0.19191921, -0.19191921, -0.19191921],\n",
      "       [-0.17171717, -0.17171717, -0.17171717],\n",
      "       [-0.15151513, -0.15151513, -0.15151513],\n",
      "       [-0.13131312, -0.13131312, -0.13131312],\n",
      "       [-0.11111113, -0.11111113, -0.11111113],\n",
      "       [-0.09090903, -0.09090903, -0.09090903],\n",
      "       [-0.07070708, -0.07070708, -0.07070708],\n",
      "       [-0.05050504, -0.05050504, -0.05050504],\n",
      "       [-0.030303  , -0.030303  , -0.030303  ],\n",
      "       [-0.01010105, -0.01010105, -0.01010105],\n",
      "       [ 0.01010096,  0.01010096,  0.01010096],\n",
      "       [ 0.030303  ,  0.030303  ,  0.030303  ],\n",
      "       [ 0.05050504,  0.05050504,  0.05050504],\n",
      "       [ 0.07070708,  0.07070708,  0.07070708],\n",
      "       [ 0.09090912,  0.09090912,  0.09090912],\n",
      "       [ 0.11111116,  0.11111116,  0.11111116],\n",
      "       [ 0.13131309,  0.13131309,  0.13131309],\n",
      "       [ 0.15151513,  0.15151513,  0.15151513],\n",
      "       [ 0.17171717,  0.17171717,  0.17171717],\n",
      "       [ 0.19191921,  0.19191921,  0.19191921],\n",
      "       [ 0.21212125,  0.21212125,  0.21212125],\n",
      "       [ 0.23232329,  0.23232329,  0.23232329],\n",
      "       [ 0.2525252 ,  0.2525252 ,  0.2525252 ],\n",
      "       [ 0.27272725,  0.27272725,  0.27272725],\n",
      "       [ 0.2929293 ,  0.2929293 ,  0.2929293 ],\n",
      "       [ 0.31313133,  0.31313133,  0.31313133],\n",
      "       [ 0.33333337,  0.33333337,  0.33333337],\n",
      "       [ 0.3535353 ,  0.3535353 ,  0.3535353 ],\n",
      "       [ 0.37373734,  0.37373734,  0.37373734],\n",
      "       [ 0.39393938,  0.39393938,  0.39393938],\n",
      "       [ 0.41414142,  0.41414142,  0.41414142],\n",
      "       [ 0.43434346,  0.43434346,  0.43434346],\n",
      "       [ 0.4545455 ,  0.4545455 ,  0.4545455 ],\n",
      "       [ 0.47474742,  0.47474742,  0.47474742],\n",
      "       [ 0.49494946,  0.49494946,  0.49494946],\n",
      "       [ 0.5151515 ,  0.5151515 ,  0.5151515 ],\n",
      "       [ 0.53535354,  0.53535354,  0.53535354],\n",
      "       [ 0.5555556 ,  0.5555556 ,  0.5555556 ],\n",
      "       [ 0.5757576 ,  0.5757576 ,  0.5757576 ],\n",
      "       [ 0.59595954,  0.59595954,  0.59595954],\n",
      "       [ 0.6161616 ,  0.6161616 ,  0.6161616 ],\n",
      "       [ 0.6363636 ,  0.6363636 ,  0.6363636 ],\n",
      "       [ 0.65656567,  0.65656567,  0.65656567],\n",
      "       [ 0.6767677 ,  0.6767677 ,  0.6767677 ],\n",
      "       [ 0.69696975,  0.69696975,  0.69696975],\n",
      "       [ 0.71717167,  0.71717167,  0.71717167],\n",
      "       [ 0.7373737 ,  0.7373737 ,  0.7373737 ],\n",
      "       [ 0.75757575,  0.75757575,  0.75757575],\n",
      "       [ 0.7777778 ,  0.7777778 ,  0.7777778 ],\n",
      "       [ 0.79797983,  0.79797983,  0.79797983],\n",
      "       [ 0.8181819 ,  0.8181819 ,  0.8181819 ],\n",
      "       [ 0.8383838 ,  0.8383838 ,  0.8383838 ],\n",
      "       [ 0.85858583,  0.85858583,  0.85858583],\n",
      "       [ 0.8787879 ,  0.8787879 ,  0.8787879 ],\n",
      "       [ 0.8989899 ,  0.8989899 ,  0.8989899 ],\n",
      "       [ 0.91919196,  0.91919196,  0.91919196],\n",
      "       [ 0.939394  ,  0.939394  ,  0.939394  ],\n",
      "       [ 0.9595959 ,  0.9595959 ,  0.9595959 ],\n",
      "       [ 0.97979796,  0.97979796,  0.97979796],\n",
      "       [ 1.        ,  1.        ,  1.        ]], dtype=float32), Array([-7.00000000e+00, -5.84441662e+00, -4.86510611e+00, -4.03799248e+00,\n",
      "       -3.34185338e+00, -2.75806189e+00, -2.27029800e+00, -1.86431289e+00,\n",
      "       -1.52770317e+00, -1.24971116e+00, -1.02103877e+00, -8.33675385e-01,\n",
      "       -6.80753887e-01, -5.56408048e-01, -4.55648571e-01, -3.74253869e-01,\n",
      "       -3.08667481e-01, -2.55911648e-01, -2.13506475e-01, -1.79399475e-01,\n",
      "       -1.51903421e-01, -1.29640877e-01, -1.11497425e-01, -9.65777040e-02,\n",
      "       -8.41703191e-02, -7.37155601e-02, -6.47781044e-02, -5.70242256e-02,\n",
      "       -5.02015203e-02, -4.41225618e-02, -3.86507921e-02, -3.36889550e-02,\n",
      "       -2.91695464e-02, -2.50469819e-02, -2.12914664e-02, -1.78837758e-02,\n",
      "       -1.48115205e-02, -1.20660337e-02, -9.64002963e-03, -7.52598047e-03,\n",
      "       -5.71476063e-03, -4.19482496e-03, -2.95158592e-03, -1.96700520e-03,\n",
      "       -1.21934502e-03, -6.83015154e-04, -3.28504859e-04, -1.22319849e-04,\n",
      "       -2.69831708e-05, -1.02021193e-06,  1.04100502e-06,  2.86696177e-05,\n",
      "        1.35332608e-04,  3.78494704e-04,  8.19620036e-04,  1.52417819e-03,\n",
      "        2.56165490e-03,  4.00561839e-03,  5.93376625e-03,  8.42809770e-03,\n",
      "        1.15751596e-02,  1.54664489e-02,  2.01989897e-02,  2.58763358e-02,\n",
      "        3.26096527e-02,  4.05195504e-02,  4.97383699e-02,  6.04131296e-02,\n",
      "        7.27097243e-02,  8.68175626e-02,  1.02956057e-01,  1.21382371e-01,\n",
      "        1.42400950e-01,  1.66374996e-01,  1.93740994e-01,  2.25024551e-01,\n",
      "        2.60860741e-01,  3.02017182e-01,  3.49421322e-01,  4.04191613e-01,\n",
      "        4.67675447e-01,  5.41489542e-01,  6.27568960e-01,  7.28222072e-01,\n",
      "        8.46192718e-01,  9.84730005e-01,  1.14767087e+00,  1.33952451e+00,\n",
      "        1.56557608e+00,  1.83199549e+00,  2.14596295e+00,  2.51580429e+00,\n",
      "        2.95115113e+00,  3.46309423e+00,  4.06438112e+00,  4.76961231e+00,\n",
      "        5.59546757e+00,  6.56094122e+00,  7.68763161e+00,  9.00000000e+00],      dtype=float32), Array([-7.84076166e+00, -8.15201473e+00, -6.39066839e+00, -3.79630804e+00,\n",
      "       -2.48079109e+00, -2.46470094e+00, -1.82317567e+00, -2.59335184e+00,\n",
      "       -1.42615008e+00, -6.80475712e-01, -1.18865371e+00, -7.46842384e-01,\n",
      "       -8.01601768e-01, -8.23274970e-01, -5.03571689e-01, -5.23404479e-01,\n",
      "       -3.19456458e-01, -1.62052229e-01, -1.99254259e-01, -1.00981690e-01,\n",
      "       -8.94668549e-02, -9.04260278e-02, -1.24605268e-01, -9.93117541e-02,\n",
      "       -9.22475904e-02, -6.83954060e-02, -8.00957754e-02, -4.23287489e-02,\n",
      "       -2.64637955e-02, -4.44796868e-02, -3.24197635e-02, -3.08627039e-02,\n",
      "       -2.62412205e-02, -1.66446995e-02, -1.34483287e-02, -1.97253693e-02,\n",
      "       -1.63114220e-02, -8.99745245e-03, -7.75610236e-03, -5.41798119e-03,\n",
      "       -6.84405351e-03, -4.37443750e-03, -3.19836824e-03, -1.42249442e-03,\n",
      "       -7.94063788e-04, -8.27612472e-04, -5.02628449e-04, -1.45110942e-04,\n",
      "       -3.59596852e-05, -1.20797438e-06,  8.61676540e-07,  3.17724916e-05,\n",
      "        1.51292450e-04,  4.90748149e-04,  8.08788405e-04,  1.03629462e-03,\n",
      "        2.19319784e-03,  4.56107175e-03,  6.09077886e-03,  5.35175344e-03,\n",
      "        9.63188987e-03,  2.09828652e-02,  2.63337754e-02,  2.59300377e-02,\n",
      "        4.77353893e-02,  4.61702794e-02,  6.20914400e-02,  3.19128856e-02,\n",
      "        1.02590516e-01,  1.15268417e-01,  7.77893960e-02,  1.45121515e-01,\n",
      "        1.20905899e-01,  1.66671932e-01,  1.91345915e-01,  1.68719321e-01,\n",
      "        2.48862118e-01,  4.29790378e-01,  3.62677276e-01,  3.48946005e-01,\n",
      "        4.99752462e-01,  8.30986261e-01,  3.70231330e-01,  8.11971545e-01,\n",
      "        9.04923797e-01,  1.05896664e+00,  1.37187278e+00,  1.20922410e+00,\n",
      "        9.14119720e-01,  1.75193608e+00,  2.75852203e+00,  2.44677687e+00,\n",
      "        2.77786183e+00,  2.55684733e+00,  3.90849829e+00,  4.12679291e+00,\n",
      "        5.28920269e+00,  5.50850439e+00,  1.19447985e+01,  8.53700924e+00],      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax.experimental import sparse\n",
    "from polynomial_generator import eval_polynomial, generate_random_polynomial, generate_training_set, eval_polynomial_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCOO(int32[2, 3, 4], nse=3)\n",
      "[0 2 1]\n",
      "[[0 3 1]\n",
      " [2 1 2]\n",
      " [0 2 4]]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "max_coeff = 3\n",
    "polynomial = generate_random_polynomial(3, [2,3,4], max_coeff)\n",
    "print(polynomial)\n",
    "print(polynomial.data)\n",
    "print(polynomial.indices)\n",
    "data = jnp.array([1,2,3])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360 360]\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "multy_data = jnp.array([[1,2,3], [1,2,3]])\n",
    "eval_multy_data = jax.vmap(lambda x: eval_polynomial(polynomial, x), in_axes=0)(multy_data)\n",
    "print(eval_multy_data)\n",
    "print(eval_polynomial(polynomial, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111]\n",
      " [0.22222222 0.22222222 0.22222222]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.44444445 0.44444445 0.44444445]\n",
      " [0.5555556  0.5555556  0.5555556 ]\n",
      " [0.6666667  0.6666667  0.6666667 ]\n",
      " [0.7777778  0.7777778  0.7777778 ]\n",
      " [0.8888889  0.8888889  0.8888889 ]\n",
      " [1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "test = jnp.linspace(np.array([0,0,0]), np.array([1,1,1]), 10)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -1.        ]\n",
      " [-0.7777778  -0.7777778  -0.7777778 ]\n",
      " [-0.5555556  -0.5555556  -0.5555556 ]\n",
      " [-0.33333328 -0.33333328 -0.33333328]\n",
      " [-0.11111113 -0.11111113 -0.11111113]\n",
      " [ 0.11111116  0.11111116  0.11111116]\n",
      " [ 0.33333337  0.33333337  0.33333337]\n",
      " [ 0.5555556   0.5555556   0.5555556 ]\n",
      " [ 0.7777778   0.7777778   0.7777778 ]\n",
      " [ 1.          1.          1.        ]]\n",
      "[8.0000000e+00 1.0713571e+00 7.2595574e-02 1.2193248e-03 1.8584487e-07\n",
      " 1.8584531e-07 1.2193273e-03 7.2595574e-02 1.0713571e+00 8.0000000e+00]\n",
      "[8.7380085e+00 9.4797015e-01 5.6895085e-02 1.5875878e-03 2.3244849e-07\n",
      " 1.4538651e-07 1.0978519e-03 6.0490094e-02 1.1615905e+00 8.7964497e+00]\n"
     ]
    }
   ],
   "source": [
    "start_samples = np.array([-1, -1, -1])\n",
    "end_samples = np.array([1, 1, 1])\n",
    "polynomial = generate_random_polynomial(1, [2, 3, 3], 10)\n",
    "x, y_pure, y_noisy = generate_training_set(polynomial, 10, start_samples, end_samples, 0.25, 42)\n",
    "print(x)\n",
    "print(y_pure)\n",
    "print(y_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3)\n",
      "[9 8 4]\n",
      "1.62921\n",
      "[(b'',) (b'',) (b'',)]\n",
      "(b'',)\n"
     ]
    }
   ],
   "source": [
    "def loss(polynomial_data, polynomial_indices, polynomial_shape, x, y):\n",
    "    polynomial = sparse.BCOO((polynomial_data, polynomial_indices), shape= polynomial_shape)\n",
    "    y_pred = eval_polynomial_vectorized(polynomial, x)\n",
    "    loss = jnp.log(jnp.sum(jnp.square(y_pred - y)))\n",
    "    return loss\n",
    "grad_loss = jax.grad(loss, allow_int=True)\n",
    "\n",
    "# def compute_loss_and_grad(param_w, data, start, stop, num_points=100):\n",
    "#     param_w_values = jnp.linspace(start, stop, num_points)\n",
    "#     loss_values = jnp.array([loss(w, data) for w in param_w_values])\n",
    "#     grad_values = jnp.array([grad_loss(w, data) for w in param_w_values])\n",
    "#     return param_w_values, loss_values, grad_values\n",
    "\n",
    "print(polynomial.shape)\n",
    "print(polynomial.data)\n",
    "test = loss(polynomial.data, polynomial.indices, polynomial.shape, x, y_noisy)\n",
    "print(test)\n",
    "grad_test = grad_loss(polynomial.data, polynomial.indices, polynomial.shape, x, y_noisy)\n",
    "print(grad_test)\n",
    "print(grad_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running Stochastic Gradient Descent =====\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('float64'), dtype([('float0', 'V')])) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     batch_y \u001b[38;5;241m=\u001b[39m y_noisy[i:i \u001b[38;5;241m+\u001b[39m num_points_per_batch]\n\u001b[1;32m     15\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad_loss(polynomial\u001b[38;5;241m.\u001b[39mdata, polynomial\u001b[38;5;241m.\u001b[39mindices, polynomial\u001b[38;5;241m.\u001b[39mshape, batch_x, batch_y)\n\u001b[0;32m---> 16\u001b[0m     param_w \u001b[38;5;241m=\u001b[39m polynomial\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m \u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: param_w=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_w\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, grad=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss(param_w,\u001b[38;5;250m \u001b[39mtrain_ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('float64'), dtype([('float0', 'V')])) -> None"
     ]
    }
   ],
   "source": [
    "# %% Run stochastic gradient descent\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "param_w = jnp.array([1.0, 1.0, 1.0])\n",
    "n_points = 10\n",
    "polynomial = generate_random_polynomial(3, [2, 3, 3], 10)\n",
    "x, y_pure, y_noisy = generate_training_set(polynomial, n_points, start_samples, end_samples, 0.25, 42)\n",
    "num_points_per_batch = n_points // 5\n",
    "print(\"\\n===== Running Stochastic Gradient Descent =====\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Get points for the current batch\n",
    "    for i in range(0, n_points, num_points_per_batch):\n",
    "        batch_x = x[i:i + num_points_per_batch]\n",
    "        batch_y = y_noisy[i:i + num_points_per_batch]\n",
    "        grad = grad_loss(polynomial.data, polynomial.indices, polynomial.shape, batch_x, batch_y)\n",
    "        param_w = polynomial.data - learning_rate * grad\n",
    "\n",
    "    print(f\"Epoch {epoch}: param_w={param_w}, grad={grad}, loss={loss(param_w, train_ds)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
